{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping USA Snow Storm Data and visualizing them using Folium\n",
    "### Samira Kumar\n",
    "### Data Source: https://data.nodc.noaa.gov/cgi-bin/iso?id=gov.noaa.ncdc:C00464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pandas\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?C=N;O=D',\n",
       " '?C=M;O=A',\n",
       " '?C=S;O=A',\n",
       " '?C=D;O=A',\n",
       " '/data/snowstorm-database/',\n",
       " 'snowstorm-db_shapefile-readme_c20130529.txt',\n",
       " 'snowstorm-db_storm-1_s19000226_e19000303_c20130514.tar.gz',\n",
       " 'snowstorm-db_storm-1_s19000304_e19000307_c20130514.tar.gz',\n",
       " 'snowstorm-db_storm-1_s19000315_e19000316_c20130514.tar.gz',\n",
       " 'snowstorm-db_storm-1_s19010201_e19010206_c20130514.tar.gz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r  = requests.get(\"https://www.ncei.noaa.gov/data/snowstorm-database/archive/\")\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data)\n",
    "\n",
    "link_a=[]\n",
    "for link in soup.find_all('a'):\n",
    "    link_a.append(link.get('href'))\n",
    "link_a[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download all files from the link\n",
    "**Links** in **link_a** start from 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<urllib.request.URLopener at 0x12472f208>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfile = urllib.request.URLopener()\n",
    "for a in link_a[6:]:\n",
    "    testfile.retrieve(\"https://www.ncei.noaa.gov/data/snowstorm-database/archive/\"+a, \"Data_Script/\"+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"Path to all unzipped folder\")\n",
    "folder_compiled = Path(\"Path to store compiled shapefile\")\n",
    "\n",
    "\n",
    "shapefiles = folder.glob(\"snowstorm-db_*/*.shp\")\n",
    "gdf_1 = pandas.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefiles = folder.glob(\"RSI_*/*/*.shp\")\n",
    "gdf_2 = pandas.concat([\n",
    "    geopandas.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(geopandas.GeoDataFrame)\n",
    "gdf_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We're using 2 separate geodataframes since the structure of folders of the data is different in old set of years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_concat=pandas.concat([gdf_1,gdf_2])\n",
    "gdf_concat.to_file(folder_compiled / 'compiled.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'd save this file in both shapfile and csv, but used only the csv to prepare the visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization using Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "from folium.plugins import TimestampedGeoJson\n",
    "import numpy as np\n",
    "import os\n",
    "import branca\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata,RectSphereBivariateSpline,Rbf\n",
    "import geojsoncontour\n",
    "import scipy as sp\n",
    "import scipy.ndimage \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('filtered_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowfall_cat=[]\n",
    "for i,v in df.iterrows():\n",
    "    sf=v['Total Snowfall']\n",
    "    if sf<2:\n",
    "        snowfall_cat.append(0)\n",
    "    elif (sf>=2) and (sf<6):\n",
    "        snowfall_cat.append(0.2)\n",
    "    elif (sf>=6) and (sf<12):\n",
    "        snowfall_cat.append(0.4)\n",
    "    elif (sf>=12) and (sf<18):\n",
    "        snowfall_cat.append(0.6)\n",
    "    elif (sf>=18) and (sf<24):\n",
    "        snowfall_cat.append(0.8)\n",
    "    else:\n",
    "        snowfall_cat.append(1)\n",
    "df['Snowfall Cat']=snowfall_cat\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~(df['Latitude']<=0)].copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below method was initially taken from Thomas Jansson's post (https://github.com/python-visualization/folium/issues/958#issuecomment-427156672) and modified to create the map for time series data.\n",
    "\n",
    "#### This creates the contour plot for the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate all years in the dataset\n",
    "data = []\n",
    "a={}\n",
    "time_not_in=[1911,1928] #these 2 years dont have data. So ignore them while checking\n",
    "min_year,max_year=int(df.Year_Start.min()),int(df.Year_Start.max())\n",
    "for i in range(1900,max_year+1):\n",
    "    if (i not in time_not_in):\n",
    "        \n",
    "        df_copy=df[df['Year_Start']==i].copy()\n",
    "        colors = ['white',  'royalblue',  'cyan',  'lime',  'yellow','red']\n",
    "        vmin   = 0\n",
    "        vmax   = 1\n",
    "        levels = len(colors)\n",
    "        cm     = branca.colormap.LinearColormap(colors, vmin=vmin, vmax=vmax).to_step(levels)\n",
    "\n",
    "        \n",
    "        x_orig = (df_copy.Longitude.values.tolist())\n",
    "        y_orig = (df_copy.Latitude.values.tolist())\n",
    "        z_orig = np.asarray(df_copy['Snowfall Cat'].values.tolist())\n",
    "\n",
    "        \n",
    "        x_arr          = np.linspace(np.min(x_orig), np.max(x_orig), 500)\n",
    "        y_arr          = np.linspace(np.min(y_orig), np.max(y_orig), 500)\n",
    "        x_mesh, y_mesh = np.meshgrid(x_arr, y_arr)\n",
    "\n",
    "        xscale = df_copy.Longitude.max() - df_copy.Longitude.min()\n",
    "        yscale = df_copy.Latitude.max() - df_copy.Latitude.min()\n",
    "\n",
    "        scale = np.array([xscale, yscale])\n",
    "\n",
    "        \n",
    "        z_mesh = griddata((x_orig, y_orig), z_orig, (x_mesh, y_mesh), method='linear')\n",
    "\n",
    "        \n",
    "        sigma = [3, 3]\n",
    "        z_mesh = sp.ndimage.filters.gaussian_filter(z_mesh, sigma, mode='nearest')\n",
    "\n",
    "        # Create the contour\n",
    "        contourf = plt.contourf(x_mesh, y_mesh, z_mesh, levels, alpha=0.5, colors=colors, \n",
    "                                linestyles='none', vmin=vmin, vmax=vmax)\n",
    "\n",
    "        # Convert matplotlib contourf to geojson\n",
    "        geojson = geojsoncontour.contourf_to_geojson(\n",
    "            contourf=contourf,\n",
    "            min_angle_deg=3.0,\n",
    "            ndigits=3,\n",
    "            unit='m',\n",
    "            stroke_width=1,\n",
    "            fill_opacity=0.3)\n",
    "        d = json.loads(geojson)\n",
    "        len_features=len(d['features'])\n",
    "        for j in range(0,len_features):\n",
    "            d['features'][j]['properties']['time']=str(i)+'-01-31'\n",
    "        if not data:\n",
    "            data.append(d)\n",
    "        else:\n",
    "            for i in range(len(d['features'])):\n",
    "                 data[0]['features'].append(d['features'][i])\n",
    "\n",
    "print (\"Completed!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below code modifies the geojson to change properties of styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_act=data[0]\n",
    "for i in range(len(dict_act['features'])):\n",
    "\n",
    "    dict_act['features'][i]['properties']['color']=dict_act['features'][i]['properties'].pop('fill')\n",
    "    dict_act['features'][i]['properties']['weight']=dict_act['features'][i]['properties'].pop('stroke-width')\n",
    "    dict_act['features'][i]['properties']['fillOpacity']=dict_act['features'][i]['properties'].pop('fill-opacity')\n",
    "    properties=dict_act['features'][i]['properties']\n",
    "    gettime=properties.pop('time')\n",
    "    new_properties = {'style': properties, 'time':gettime}\n",
    "    dict_act['features'][i]['properties']=new_properties\n",
    "    \n",
    "print('Completed!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geomap = folium.Map([39, -99], zoom_start=4.5, tiles=\"cartodbpositron\")\n",
    "\n",
    "#{'type': 'FeatureCollection',\n",
    " #       'features': features}\n",
    "TimestampedGeoJson(\n",
    "    dict_act,\n",
    "    period='P1Y',\n",
    "    duration='P1M',\n",
    "    auto_play=False,\n",
    "    date_options='YYYY'\n",
    "    ).add_to(geomap)#date_options='YYYY'\n",
    "\n",
    "# Add the colormap to the folium map\n",
    "cm.caption = 'Snowfall Category'\n",
    "geomap.add_child(cm)\n",
    "\n",
    "# Fullscreen mode\n",
    "plugins.Fullscreen(position='topright', force_separate_button=True).add_to(geomap)\n",
    "\n",
    "# Plot the data\n",
    "geomap.save('folium_contour_time.html')\n",
    "\n",
    "print('Completed!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Visualisation:\n",
    "## https://samirak93.github.io/snow/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
